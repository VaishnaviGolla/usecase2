{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99e0d434",
   "metadata": {},
   "source": [
    "### **Project 2: Classification Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea57ad05",
   "metadata": {},
   "source": [
    "One of the largest public sector banks which has several branches across cities provides various services like savings accounts, current accounts, term deposits, personal loans, home loans etc. to customers. Whenever the bank conducts marketing on its new schemes, it will keep track of data related to customers’ personal, social and economic details. Also, it maintains the detailing on efforts made to achieve success in the campaign. Recently, the bank has conducted a campaign to market their term-deposit scheme. Campaigns were conducted based mostly on direct phone calls, soliciting the bank's customers to place a term deposit. After all the marketing efforts, if the client had agreed to place a deposit, then the campaign is a success, otherwise not (Target variable marked 'yes', or 'no'). It is a challenge for bank officials to target the right people for a successful campaign. \n",
    "\n",
    "Tasks:\n",
    "1. Data loading, data cleaning and report analysis. (Weightage 30 Marks)\n",
    "2. Building ML-  Classification Model. (Weightage 70 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f035d1a2",
   "metadata": {},
   "source": [
    "Data Dictionary:\n",
    "\n",
    "Age:\t(numeric)\n",
    "Job:\tType of job (categorical: 'admin.', 'blue-collar', 'entrepreneur', 'housemaid', 'management', 'retired', 'self-employed',\n",
    " \t'services', 'student', 'technician', 'unemployed', 'unknown')\n",
    "Marital :\tMarital status (categorical: 'divorced', 'married', 'single', 'unknown';Note: 'divorced' means divorced or widowed)\n",
    "Education:\t(categorical: 'basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'illiterate', \t'professional.course', 'university.degree', 'unknown')\n",
    "Default:\tHas credit in default? (categorical: 'no', 'yes', 'unknown')\n",
    "Housing:\tHas housing loan? (categorical: 'no', 'yes', 'unknown')\n",
    "Loan:\tHas personal loan? (categorical: 'no', 'yes', 'unknown')\n",
    "Contact:\tContact communication type (categorical: 'cellular', 'telephone')\n",
    "Month:\tLast contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "Day_of_week:\tlast contact day of the week (categorical: 'mon', 'tue', 'wed', 'thu', 'fri')\n",
    "Duration:\tLast contact duration, in seconds (numeric).\n",
    " \tImportant note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "Campaign:\tNumber of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "Pdays:\tNumber of days that passed by after the client was last contacted from a previous campaign: (numeric; 999 means client was not previously contacted)\n",
    "Previous:\tnumber of contacts performed before this campaign and for this client (numeric)\n",
    "Poutcome:\toutcome of the previous marketing campaign (categorical:\n",
    " \t'failure', 'nonexistent', 'success')\n",
    "Output variable (desired target):\n",
    "Y:\thas the client subscribed a term deposit? (binary: 'yes', 'no')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3099b693",
   "metadata": {},
   "source": [
    "**Initial Guidelines:**\n",
    "\n",
    "1. Ensure to follow to Use Id’s provided by UNext for naming file as conventions.\n",
    "2. Create GitHub account and submit the GitHub link."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bdc4e0",
   "metadata": {},
   "source": [
    "### Software Engineering aspect:  \n",
    "\n",
    "Utilize software engineering aspects while building Machine learning model using modular programming principles to organize your code into reusable functions or classes to enhance readability, maintainability, and collaboration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c00c34",
   "metadata": {},
   "source": [
    "### General Instructions\n",
    "\n",
    "- The cells in the Jupyter notebook can be executed any number of times for testing the solution\n",
    "- Refrain from modifying the boilerplate code as it may lead to unexpected behavior\n",
    "- The solution is to be written between the comments `# code starts here` and `# code ends here`\n",
    "- On completing all the questions, the assessment is to be submitted on moodle for evaluation\n",
    "- Before submitting the assessment, there should be `no error` while executing the notebook. If there are any error causing code, please comment it.\n",
    "- The kernel of the Jupyter notebook is to be set as `Python 3 (ipykernel)` if not set already\n",
    "- Include imports as necessary\n",
    "- For each of the task, `Note` section will provide you hints to solve the problem.\n",
    "- Do not use `PRINT` statement inside the `Except` Block. Please use `return` statement only within the except block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2f6bf",
   "metadata": {},
   "source": [
    "#### **Utilize software engineering aspects while building Machine learning model using modular programming principles to organize your code into reusable functions or classes to enhance readability, maintainability, and collaboration.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e995c31a",
   "metadata": {},
   "source": [
    "### Loading required libraries and packages "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b12073",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "Import various libraries and modules used in data analysis, machine learning, and visualization tasks in Python such as `pandas`, `numpy`, `sklearn`, `sklearn.preprocessing`,`seaborn`,`matplotlib`.There are 2 ways to import the libraries and modules:\n",
    "* import numpy as np\n",
    "* from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938faa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76d228b",
   "metadata": {},
   "source": [
    "### Task 1: Load the dataset and perform preliminary EDA (Exploratory Data Analysis) with key observations and insights- (weightage - 15 marks) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f0ed13",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "\n",
    "Loading the dataset for model building is the initial step in the machine learning pipeline, where the relevant data is imported into the chosen programming environment or framework. This process typically involves reading the dataset from a file (e.g., CSV, Excel, JSON) or fetching it from a database. Once loaded, the dataset is often inspected to understand its structure, including the number of samples, features, and target variables. Furthermore, preprocessing steps such as cleaning, handling missing values, encoding categorical variables, and scaling may be performed on the dataset to prepare it for model training. Loading the dataset accurately and efficiently is crucial for building accurate and robust machine learning models that effectively capture the underlying patterns and relationships within the data.\n",
    "\n",
    "- Do not use PRINT statement inside the Except Block. Please use `return` statement only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1951503e",
   "metadata": {},
   "source": [
    "#### T1. Import following datasets      (Weightage- 3 marks)  (AE)\n",
    "-    customer_and_bankdetails\n",
    "-    customer_campaign_details\n",
    "-    customer_response_data\n",
    "-    customer_social_economic_data\n",
    "-    customer_postal_code_details\n",
    "-   state_master\n",
    "-    region_code_master\n",
    "-    city_master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89b43caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_the_dataset_customer_and_bank_details():\n",
    "    customer_and_bankdetails = None\n",
    "    try:\n",
    "        customer_and_bankdetails=pd.read_csv('/home/labuser/Desktop/Project/Datasets/Customer_and_bank_details.csv')\n",
    "    except Exception as e:\n",
    "        return \"Check with file\"\n",
    "    \n",
    "    return customer_and_bankdetails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa18a565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_id  age          job  marital            education  default  \\\n",
      "0            1   56     services  married          high.school       no   \n",
      "1            2   45     services  married             basic.9y  unknown   \n",
      "2            3   59       admin.  married  professional.course       no   \n",
      "3            4   41  blue-collar  married              unknown  unknown   \n",
      "4            5   24   technician   single  professional.course       no   \n",
      "\n",
      "  housing loan Region_Code State_Code City_Code  \n",
      "0      no  yes           3         S1        C1  \n",
      "1      no   no           3         S1        C1  \n",
      "2      no   no           4         S2        C2  \n",
      "3      no   no           3         S3        C3  \n",
      "4     yes   no           3         S3        C3  \n"
     ]
    }
   ],
   "source": [
    "#store the result of the dataset\n",
    "customer_and_bankdetails=load_the_dataset_customer_and_bank_details()\n",
    "\n",
    "print(customer_and_bankdetails.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "562cf979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to import Customer_campaign_details\n",
    "\n",
    "def load_the_dataset_customer_campaign():\n",
    "    Customer_campaign_details = None\n",
    "    # Code starts here\n",
    "    try:\n",
    "        Customer_campaign_details=pd.read_csv('/home/labuser/Desktop/Project/Datasets/Customer_campaign_details.csv')\n",
    "    except Exception as e:\n",
    "        return \"Check with file\"\n",
    "    # code ends here\n",
    "    return Customer_campaign_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39fc6d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_id    contact month day_of_week  duration  campaign  pdays  \\\n",
      "0            1  telephone   may         mon       307         1    999   \n",
      "1            2  telephone   may         mon       198         1    999   \n",
      "2            3  telephone   may         mon       139         1    999   \n",
      "3            4  telephone   may         mon       217         1    999   \n",
      "4            5  telephone   may         mon       380         1    999   \n",
      "\n",
      "   previous     poutcome  \n",
      "0         0  nonexistent  \n",
      "1         0  nonexistent  \n",
      "2         0  nonexistent  \n",
      "3         0  nonexistent  \n",
      "4         0  nonexistent  \n"
     ]
    }
   ],
   "source": [
    "# store the result of the dataset\n",
    "Customer_campaign_details=load_the_dataset_customer_campaign()\n",
    "print(Customer_campaign_details.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfe1dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to import Customer_Response_data\n",
    "\n",
    "def load_the_dataset_customer_response():\n",
    "    Customer_Response_data = None\n",
    "    # Code starts here\n",
    "    try:\n",
    "        Customer_Response_data=pd.read_csv('/home/labuser/Desktop/Project/Datasets/Customer_Response_data.csv')\n",
    "    except Exception as e:\n",
    "        return \"Check with file\"\n",
    "    # code ends here\n",
    "    return Customer_Response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1b04fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_id   y\n",
      "0            1  no\n",
      "1            2  no\n",
      "2            3  no\n",
      "3            4  no\n",
      "4            5  no\n"
     ]
    }
   ],
   "source": [
    "# store the result of the dataset\n",
    "Customer_Response_data=load_the_dataset_customer_response()\n",
    "print(Customer_Response_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "134dc50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to import Customer_social_economic_data\n",
    "\n",
    "def load_the_dataset_customer_social_economic_data():\n",
    "    Customer_social_economic_data = None\n",
    "    # Code starts here\n",
    "    try:\n",
    "        Customer_social_economic_data=pd.read_csv('/home/labuser/Desktop/Project/Datasets/Customer_social_economic_data.csv')\n",
    "    except Exception as e:\n",
    "        return \"Check with file\"\n",
    "\n",
    "    # code ends here\n",
    "    return Customer_social_economic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ad5e004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_id  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
      "0            1           1.1          93.994          -36.4      4.857   \n",
      "1            2           1.1          93.994          -36.4      4.857   \n",
      "2            3           1.1          93.994          -36.4      4.857   \n",
      "3            4           1.1          93.994          -36.4      4.857   \n",
      "4            5           1.1          93.994          -36.4      4.857   \n",
      "\n",
      "   nr.employed  \n",
      "0       5191.0  \n",
      "1       5191.0  \n",
      "2       5191.0  \n",
      "3       5191.0  \n",
      "4       5191.0  \n"
     ]
    }
   ],
   "source": [
    "# store the result of the dataset\n",
    "Customer_social_economic_data=load_the_dataset_customer_social_economic_data()\n",
    "print(Customer_social_economic_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9853a275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to import Customer_Postal_Code_details\n",
    "\n",
    "def load_the_dataset_customer_postal_code():\n",
    "    Customer_Postal_Code_details = None\n",
    "    # Code starts here\n",
    "    try:\n",
    "        Customer_Postal_Code_details=pd.read_csv('/home/labuser/Desktop/Project/Datasets/Customer_Postal_Code_details.csv')\n",
    "    except Exception as e:\n",
    "        return \"Check with file\"\n",
    "    # code ends here\n",
    "    return Customer_Postal_Code_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c64fc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id  Postal Code\n",
      "0            1        42420\n",
      "1            2        42420\n",
      "2            3        90036\n",
      "3            4        33311\n",
      "4            5        33311\n"
     ]
    }
   ],
   "source": [
    "# store the result of the dataset\n",
    "Customer_Postal_Code_details=load_the_dataset_customer_postal_code()\n",
    "print(Customer_Postal_Code_details.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d444f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to import State_Master\n",
    "def load_the_dataset_state_master():\n",
    "    State_Master = None\n",
    "    # Code starts here\n",
    "    try:\n",
    "        State_Master=pd.read_csv('/home/labuser/Desktop/Project/Datasets/State_Master.csv')\n",
    "    except Exception as e:\n",
    "        return \"Check with file\"\n",
    "    # code ends here\n",
    "    return State_Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a1dc89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  State_Code      State_Name  Region_Code\n",
      "0         S1        Kentucky            3\n",
      "1         S2      California            4\n",
      "2         S3         Florida            3\n",
      "3         S4  North Carolina            3\n",
      "4         S5      Washington            4\n"
     ]
    }
   ],
   "source": [
    "# store the result of the dataset\n",
    "State_Master=load_the_dataset_state_master()\n",
    "print(State_Master.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0dcc0faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to import Region_code_master\n",
    "def load_the_dataset_region_code_master():\n",
    "    Region_code_master = None\n",
    "    # Code starts here\n",
    "    try:\n",
    "        Region_code_master=pd.read_csv('/home/labuser/Desktop/Project/Datasets/Region_code_master.csv')\n",
    "    except Exception as e:\n",
    "        return \"Check with file\"\n",
    "    # code ends here\n",
    "    return Region_code_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca025344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Region_Name  Region_Code\n",
      "0     Central            1\n",
      "1        East            2\n",
      "2       South            3\n",
      "3        West            4\n",
      "4       North            5\n"
     ]
    }
   ],
   "source": [
    "# store the result of the dataset\n",
    "Region_code_master=load_the_dataset_region_code_master()\n",
    "print(Region_code_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "473bef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to import City_Master\n",
    "def load_the_dataset_city_master():\n",
    "    City_Master = None\n",
    "    # Code starts here\n",
    "    try:\n",
    "        City_Master=pd.read_csv('/home/labuser/Desktop/Project/Datasets/City_Master.csv')\n",
    "    except Exception as e:\n",
    "        return \"Check with file\"\n",
    "    # code ends here\n",
    "    return City_Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b478eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  City_Code        City_Name State_Code\n",
      "0        C1        Henderson         S1\n",
      "1        C2      Los Angeles         S2\n",
      "2        C3  Fort Lauderdale         S3\n",
      "3        C4          Concord         S4\n",
      "4        C5          Seattle         S5\n"
     ]
    }
   ],
   "source": [
    "# store the result of the dataset\n",
    "City_Master=load_the_dataset_city_master()\n",
    "print(City_Master.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f727d2",
   "metadata": {},
   "source": [
    "#### change column name of dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8595d65",
   "metadata": {},
   "source": [
    "* change the column_names in the Dataframe from 'customer_id'to 'Customer_id' wherever necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3433c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modname():\n",
    "    Custom = None\n",
    "    # Code starts here\n",
    "    Custom=Customer_Postal_Code_details.rename(columns={'customer_id':'Customer_id'})\n",
    "    # Code ends here\n",
    "    return Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "abcebbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Customer_id  Postal Code\n",
      "0                1        42420\n",
      "1                2        42420\n",
      "2                3        90036\n",
      "3                4        33311\n",
      "4                5        33311\n",
      "...            ...          ...\n",
      "37079        37080        10009\n",
      "37080        37081        10011\n",
      "37081        37082        10009\n",
      "37082        37083        85254\n",
      "37083        37084        79109\n",
      "\n",
      "[37084 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "Custom=modname()\n",
    "print(Custom)\n",
    "#print(Customer_Postal_Code_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33889a3",
   "metadata": {},
   "source": [
    "#### T1.2. Create the updated dataframes by using relevant merging options and validate.  (Weightage-  8 marks) (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e0c26d",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Design the functions, custom_merge1(df1, df2),custom_merge2(df1, df2),custom_merge3(df1, df2),custom_merge4(df1, df2),custom_merge5(df1, df2),custom_merge6(df1, df2),custom_merge7(df1, df2) to merges two DataFrames (df1 and df2) based on a common column using an inner join.\n",
    "- Custom merge function\n",
    "- Hint: Inner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9a9fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_merge1(df1,df2):\n",
    "    merged_df = None\n",
    "    # Code starts here\n",
    "    merged_df=pd.merge(customer_and_bankdetails,Customer_campaign_details)\n",
    "    # Code ends here\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d0f218c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_id  age          job  marital            education  default  \\\n",
      "0            1   56     services  married          high.school       no   \n",
      "1            2   45     services  married             basic.9y  unknown   \n",
      "2            3   59       admin.  married  professional.course       no   \n",
      "3            4   41  blue-collar  married              unknown  unknown   \n",
      "4            5   24   technician   single  professional.course       no   \n",
      "\n",
      "  housing loan Region_Code State_Code City_Code    contact month day_of_week  \\\n",
      "0      no  yes           3         S1        C1  telephone   may         mon   \n",
      "1      no   no           3         S1        C1  telephone   may         mon   \n",
      "2      no   no           4         S2        C2  telephone   may         mon   \n",
      "3      no   no           3         S3        C3  telephone   may         mon   \n",
      "4     yes   no           3         S3        C3  telephone   may         mon   \n",
      "\n",
      "   duration  campaign  pdays  previous     poutcome  \n",
      "0       307         1    999         0  nonexistent  \n",
      "1       198         1    999         0  nonexistent  \n",
      "2       139         1    999         0  nonexistent  \n",
      "3       217         1    999         0  nonexistent  \n",
      "4       380         1    999         0  nonexistent  \n"
     ]
    }
   ],
   "source": [
    "# Call the custom function\n",
    "result_df = custom_merge1(customer_and_bankdetails,Customer_campaign_details)\n",
    "print(result_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "90d30711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37084, 19)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9704f3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37084, 11)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_and_bankdetails.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d1260f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37084, 9)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Customer_campaign_details.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "faa4694f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_id</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>State_Code</th>\n",
       "      <th>City_Code</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>S1</td>\n",
       "      <td>C1</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>S1</td>\n",
       "      <td>C1</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>S2</td>\n",
       "      <td>C2</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>S3</td>\n",
       "      <td>C3</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>S3</td>\n",
       "      <td>C3</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>380</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37079</th>\n",
       "      <td>37080</td>\n",
       "      <td>73</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>S16</td>\n",
       "      <td>C21</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>334</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37080</th>\n",
       "      <td>37081</td>\n",
       "      <td>46</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>S16</td>\n",
       "      <td>C21</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>383</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37081</th>\n",
       "      <td>37082</td>\n",
       "      <td>56</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>S16</td>\n",
       "      <td>C21</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>189</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37082</th>\n",
       "      <td>37083</td>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>S17</td>\n",
       "      <td>C49</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>442</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37083</th>\n",
       "      <td>37084</td>\n",
       "      <td>74</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>S6</td>\n",
       "      <td>C113</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>239</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37084 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Customer_id  age          job  marital            education  default  \\\n",
       "0                1   56     services  married          high.school       no   \n",
       "1                2   45     services  married             basic.9y  unknown   \n",
       "2                3   59       admin.  married  professional.course       no   \n",
       "3                4   41  blue-collar  married              unknown  unknown   \n",
       "4                5   24   technician   single  professional.course       no   \n",
       "...            ...  ...          ...      ...                  ...      ...   \n",
       "37079        37080   73      retired  married  professional.course       no   \n",
       "37080        37081   46  blue-collar  married  professional.course       no   \n",
       "37081        37082   56      retired  married    university.degree       no   \n",
       "37082        37083   44   technician  married  professional.course       no   \n",
       "37083        37084   74      retired  married  professional.course       no   \n",
       "\n",
       "      housing loan Region_Code State_Code City_Code    contact month  \\\n",
       "0          no  yes           3         S1        C1  telephone   may   \n",
       "1          no   no           3         S1        C1  telephone   may   \n",
       "2          no   no           4         S2        C2  telephone   may   \n",
       "3          no   no           3         S3        C3  telephone   may   \n",
       "4         yes   no           3         S3        C3  telephone   may   \n",
       "...       ...  ...         ...        ...       ...        ...   ...   \n",
       "37079     yes   no           2        S16       C21   cellular   nov   \n",
       "37080      no   no           2        S16       C21   cellular   nov   \n",
       "37081     yes   no           2        S16       C21   cellular   nov   \n",
       "37082      no   no           4        S17       C49   cellular   nov   \n",
       "37083     yes   no           1         S6      C113   cellular   nov   \n",
       "\n",
       "      day_of_week  duration  campaign  pdays  previous     poutcome    y  \n",
       "0             mon       307         1    999         0  nonexistent   no  \n",
       "1             mon       198         1    999         0  nonexistent   no  \n",
       "2             mon       139         1    999         0  nonexistent   no  \n",
       "3             mon       217         1    999         0  nonexistent   no  \n",
       "4             mon       380         1    999         0  nonexistent   no  \n",
       "...           ...       ...       ...    ...       ...          ...  ...  \n",
       "37079         fri       334         1    999         0  nonexistent  yes  \n",
       "37080         fri       383         1    999         0  nonexistent   no  \n",
       "37081         fri       189         2    999         0  nonexistent   no  \n",
       "37082         fri       442         1    999         0  nonexistent  yes  \n",
       "37083         fri       239         3    999         1      failure   no  \n",
       "\n",
       "[37084 rows x 20 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df=pd.merge(result_df,Customer_Response_data,how='inner')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3ed4be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Dataframe: df2=df1 and customer_response_data\n",
    "# Hint: Inner\n",
    "# Validate rows and columns numbers = [37084 rows x 20 columns]\n",
    "def custom_merge2(df1,df2):\n",
    "    merged_df = None\n",
    "    # Code starts here\n",
    "    merged_df=pd.merge(result_df,Customer_Response_data,how='inner')\n",
    "    # Code ends here\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1505ab6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_id  age          job  marital            education  default  \\\n",
      "0            1   56     services  married          high.school       no   \n",
      "1            2   45     services  married             basic.9y  unknown   \n",
      "2            3   59       admin.  married  professional.course       no   \n",
      "3            4   41  blue-collar  married              unknown  unknown   \n",
      "4            5   24   technician   single  professional.course       no   \n",
      "\n",
      "  housing loan Region_Code State_Code City_Code    contact month day_of_week  \\\n",
      "0      no  yes           3         S1        C1  telephone   may         mon   \n",
      "1      no   no           3         S1        C1  telephone   may         mon   \n",
      "2      no   no           4         S2        C2  telephone   may         mon   \n",
      "3      no   no           3         S3        C3  telephone   may         mon   \n",
      "4     yes   no           3         S3        C3  telephone   may         mon   \n",
      "\n",
      "   duration  campaign  pdays  previous     poutcome   y  \n",
      "0       307         1    999         0  nonexistent  no  \n",
      "1       198         1    999         0  nonexistent  no  \n",
      "2       139         1    999         0  nonexistent  no  \n",
      "3       217         1    999         0  nonexistent  no  \n",
      "4       380         1    999         0  nonexistent  no  \n"
     ]
    }
   ],
   "source": [
    "# Call the custom function\n",
    "result_df1 = custom_merge2(result_df,Customer_Response_data)\n",
    "print(result_df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "233e23cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37084, 20)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7df782cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third Dataframe: df3=df2 and customer_social_economic_data\n",
    "# Validate rows and columns numbers = [37084 rows x 25 columns]\n",
    "# Hint: Inner\n",
    "def custom_merge3(df1,df2):\n",
    "    merged_df = None\n",
    "    # Code starts here\n",
    "    merged_df=pd.merge(result_df1,Customer_social_economic_data)\n",
    "    # Code ends here\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e3b94c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_id  age          job  marital            education  default  \\\n",
      "0            1   56     services  married          high.school       no   \n",
      "1            2   45     services  married             basic.9y  unknown   \n",
      "2            3   59       admin.  married  professional.course       no   \n",
      "3            4   41  blue-collar  married              unknown  unknown   \n",
      "4            5   24   technician   single  professional.course       no   \n",
      "\n",
      "  housing loan Region_Code State_Code  ... campaign pdays previous  \\\n",
      "0      no  yes           3         S1  ...        1   999        0   \n",
      "1      no   no           3         S1  ...        1   999        0   \n",
      "2      no   no           4         S2  ...        1   999        0   \n",
      "3      no   no           3         S3  ...        1   999        0   \n",
      "4     yes   no           3         S3  ...        1   999        0   \n",
      "\n",
      "      poutcome   y  emp.var.rate  cons.price.idx  cons.conf.idx euribor3m  \\\n",
      "0  nonexistent  no           1.1          93.994          -36.4     4.857   \n",
      "1  nonexistent  no           1.1          93.994          -36.4     4.857   \n",
      "2  nonexistent  no           1.1          93.994          -36.4     4.857   \n",
      "3  nonexistent  no           1.1          93.994          -36.4     4.857   \n",
      "4  nonexistent  no           1.1          93.994          -36.4     4.857   \n",
      "\n",
      "  nr.employed  \n",
      "0      5191.0  \n",
      "1      5191.0  \n",
      "2      5191.0  \n",
      "3      5191.0  \n",
      "4      5191.0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Call the custom function\n",
    "result_df2 = custom_merge3(result_df1,Customer_social_economic_data)\n",
    "print(result_df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "37a6bcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37084, 25)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "214fa177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fourth Dataframe: df4= df3 and customer_postal_code_details\n",
    "#Validate rows and columns numbers = [37084 rows x 26 columns]\n",
    "#Hint: Inner\n",
    "\n",
    "def custom_merge4(df1,df2):\n",
    "    merged_df = None\n",
    "    # Code starts here\n",
    "    merged_df=pd.merge(result_df2,Custom)\n",
    "    # Code ends here\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "764bda12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_id  age          job  marital            education  default  \\\n",
      "0            1   56     services  married          high.school       no   \n",
      "1            2   45     services  married             basic.9y  unknown   \n",
      "2            3   59       admin.  married  professional.course       no   \n",
      "3            4   41  blue-collar  married              unknown  unknown   \n",
      "4            5   24   technician   single  professional.course       no   \n",
      "\n",
      "  housing loan Region_Code State_Code  ... pdays previous     poutcome   y  \\\n",
      "0      no  yes           3         S1  ...   999        0  nonexistent  no   \n",
      "1      no   no           3         S1  ...   999        0  nonexistent  no   \n",
      "2      no   no           4         S2  ...   999        0  nonexistent  no   \n",
      "3      no   no           3         S3  ...   999        0  nonexistent  no   \n",
      "4     yes   no           3         S3  ...   999        0  nonexistent  no   \n",
      "\n",
      "   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m nr.employed  \\\n",
      "0           1.1          93.994          -36.4      4.857      5191.0   \n",
      "1           1.1          93.994          -36.4      4.857      5191.0   \n",
      "2           1.1          93.994          -36.4      4.857      5191.0   \n",
      "3           1.1          93.994          -36.4      4.857      5191.0   \n",
      "4           1.1          93.994          -36.4      4.857      5191.0   \n",
      "\n",
      "  Postal Code  \n",
      "0       42420  \n",
      "1       42420  \n",
      "2       90036  \n",
      "3       33311  \n",
      "4       33311  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Call the custom function\n",
    "result_df3 = custom_merge4(result_df2,Custom)\n",
    "print(result_df3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3062664c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37084, 26)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6617d4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fifth Dataframe: df5= state_master and region_code_master\n",
    "#Validate rows and columns numbers = 49 rows and 4 columns\n",
    "#Hint: Left\n",
    "def custom_merge5(df1,df2):\n",
    "    merged_df = None\n",
    "    # Code starts here\n",
    "    merged_df=pd.merge(State_Master,Region_code_master)\n",
    "    # Code ends here\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "849c488d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   State_Code            State_Name  Region_Code Region_Name\n",
      "0          S1              Kentucky            3       South\n",
      "1          S3               Florida            3       South\n",
      "2          S4        North Carolina            3       South\n",
      "3         S18              Virginia            3       South\n",
      "4         S19             Tennessee            3       South\n",
      "5         S20               Alabama            3       South\n",
      "6         S21        South Carolina            3       South\n",
      "7         S29             Louisiana            3       South\n",
      "8         S33               Georgia            3       South\n",
      "9         S36           Mississippi            3       South\n",
      "10        S37              Arkansas            3       South\n",
      "11         S2            California            4        West\n",
      "12         S5            Washington            4        West\n",
      "13         S8                  Utah            4        West\n",
      "14        S17               Arizona            4        West\n",
      "15        S22                Oregon            4        West\n",
      "16        S23              Colorado            4        West\n",
      "17        S28            New Mexico            4        West\n",
      "18        S34                Nevada            4        West\n",
      "19        S38               Montana            4        West\n",
      "20        S46                 Idaho            4        West\n",
      "21        S48               Wyoming            4        West\n",
      "22         S6                 Texas            1     Central\n",
      "23         S7             Wisconsin            1     Central\n",
      "24         S9              Nebraska            1     Central\n",
      "25        S11              Illinois            1     Central\n",
      "26        S12             Minnesota            1     Central\n",
      "27        S13              Michigan            1     Central\n",
      "28        S15               Indiana            1     Central\n",
      "29        S24                  Iowa            1     Central\n",
      "30        S26              Missouri            1     Central\n",
      "31        S27              Oklahoma            1     Central\n",
      "32        S42                Kansas            1     Central\n",
      "33        S45          South Dakota            1     Central\n",
      "34        S47          North Dakota            1     Central\n",
      "35        S10          Pennsylvania            2        East\n",
      "36        S14              Delaware            2        East\n",
      "37        S16              New York            2        East\n",
      "38        S25                  Ohio            2        East\n",
      "39        S30           Connecticut            2        East\n",
      "40        S31            New Jersey            2        East\n",
      "41        S32         Massachusetts            2        East\n",
      "42        S35          Rhode Island            2        East\n",
      "43        S39         New Hampshire            2        East\n",
      "44        S40              Maryland            2        East\n",
      "45        S41  District of Columbia            2        East\n",
      "46        S43               Vermont            2        East\n",
      "47        S44                 Maine            2        East\n",
      "48        S49         West Virginia            2        East\n"
     ]
    }
   ],
   "source": [
    "# Call the custom function\n",
    "result_df4 = custom_merge5(State_Master,Region_code_master)\n",
    "print(result_df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d48148b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_merge6(df1,df2):\n",
    "    merged_df = None\n",
    "    # Code starts here\n",
    "    merged_df=pd.merge(City_Master,result_df4)\n",
    "    # Code ends here\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "eee39c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    City_Code      City_Name State_Code     State_Name  Region_Code  \\\n",
      "0          C1      Henderson         S1       Kentucky            3   \n",
      "1        C103       Richmond         S1       Kentucky            3   \n",
      "2        C160       Florence         S1       Kentucky            3   \n",
      "3        C209         Murray         S1       Kentucky            3   \n",
      "4        C257  Bowling Green         S1       Kentucky            3   \n",
      "..        ...            ...        ...            ...          ...   \n",
      "526      C461       Caldwell        S46          Idaho            4   \n",
      "527      C514     Twin Falls        S46          Idaho            4   \n",
      "528      C403          Fargo        S47   North Dakota            1   \n",
      "529      C459       Cheyenne        S48        Wyoming            4   \n",
      "530      C463         Nashua        S39  New Hampshire            2   \n",
      "\n",
      "    Region_Name  \n",
      "0         South  \n",
      "1         South  \n",
      "2         South  \n",
      "3         South  \n",
      "4         South  \n",
      "..          ...  \n",
      "526        West  \n",
      "527        West  \n",
      "528     Central  \n",
      "529        West  \n",
      "530        East  \n",
      "\n",
      "[531 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Call the custom function\n",
    "result_df5 = custom_merge6(City_Master,result_df4)\n",
    "print(result_df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "906abbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_merge7(df1,df2):\n",
    "    merged_df = None\n",
    "    # Code starts here\n",
    "    merged_df=pd.merge(result_df3,result_df5,on='City_Code')\n",
    "\n",
    "    # Code ends here\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a6a3c62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Region_Code', 'City_Code', 'State_Code'}\n"
     ]
    }
   ],
   "source": [
    "common_cols=set(result_df3.columns)&set(result_df5.columns)\n",
    "print(common_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e94a6f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result_df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "66732a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result_df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6e791cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Customer_id  age          job   marital          education  default  \\\n",
      "0                1   56     services   married        high.school       no   \n",
      "1                2   45     services   married           basic.9y  unknown   \n",
      "2              539   32       admin.    single  university.degree       no   \n",
      "3              540   36     services   married        high.school       no   \n",
      "4              997   31  blue-collar   married           basic.9y       no   \n",
      "...            ...  ...          ...       ...                ...      ...   \n",
      "37079        19864   47       admin.  divorced  university.degree       no   \n",
      "37080        19865   58      retired   married           basic.4y       no   \n",
      "37081        29857   35       admin.   married        high.school       no   \n",
      "37082        29858   38   technician   married        high.school       no   \n",
      "37083        29859   50      unknown   married           basic.4y  unknown   \n",
      "\n",
      "      housing loan Region_Code_x State_Code_x  ... cons.price.idx  \\\n",
      "0          no  yes             3           S1  ...         93.994   \n",
      "1          no   no             3           S1  ...         93.994   \n",
      "2          no   no             3           S1  ...         93.994   \n",
      "3          no   no             3           S1  ...         93.994   \n",
      "4          no   no             3           S1  ...         93.994   \n",
      "...       ...  ...           ...          ...  ...            ...   \n",
      "37079      no   no             2          S25  ...         93.444   \n",
      "37080     yes   no             2          S25  ...         93.444   \n",
      "37081     yes   no             2          S25  ...         92.893   \n",
      "37082     yes   no             2          S25  ...         92.893   \n",
      "37083     yes   no             2          S25  ...         92.893   \n",
      "\n",
      "      cons.conf.idx euribor3m nr.employed  Postal Code  City_Name  \\\n",
      "0             -36.4     4.857      5191.0        42420  Henderson   \n",
      "1             -36.4     4.857      5191.0        42420  Henderson   \n",
      "2             -36.4     4.857      5191.0        42420  Henderson   \n",
      "3             -36.4     4.857      5191.0        42420  Henderson   \n",
      "4             -36.4     4.856      5191.0        42420  Henderson   \n",
      "...             ...       ...         ...          ...        ...   \n",
      "37079         -36.1     4.964      5228.1        45040      Mason   \n",
      "37080         -36.1     4.964      5228.1        45040      Mason   \n",
      "37081         -46.2     1.291      5099.1        45040      Mason   \n",
      "37082         -46.2     1.291      5099.1        45040      Mason   \n",
      "37083         -46.2     1.291      5099.1        45040      Mason   \n",
      "\n",
      "       State_Code_y  State_Name Region_Code_y Region_Name  \n",
      "0                S1    Kentucky             3       South  \n",
      "1                S1    Kentucky             3       South  \n",
      "2                S1    Kentucky             3       South  \n",
      "3                S1    Kentucky             3       South  \n",
      "4                S1    Kentucky             3       South  \n",
      "...             ...         ...           ...         ...  \n",
      "37079           S25        Ohio             2        East  \n",
      "37080           S25        Ohio             2        East  \n",
      "37081           S25        Ohio             2        East  \n",
      "37082           S25        Ohio             2        East  \n",
      "37083           S25        Ohio             2        East  \n",
      "\n",
      "[37084 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Call the custom function\n",
    "df = custom_merge7(result_df3,result_df5)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c606aa",
   "metadata": {},
   "source": [
    "#### Refer to the Github document from Lumen to create the repository and steps to commit \n",
    "\n",
    "#### Add your Github repository link below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9035638e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37ce7139",
   "metadata": {},
   "source": [
    "#### T1.3. Export the final data frame df to GitHub for versioning.  (Weightage-2 marks) ME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee0fef4",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "\n",
    "- Design a function `export_to_csv` export the DataFrame to a CSV file with the specified filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "52bc13bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_csv(df, filename):\n",
    "\n",
    "    \"\"\"\n",
    "    Exports a Pandas DataFrame to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to export.\n",
    "        filename (str): The desired filename for the CSV file.\n",
    "    \"\"\"\n",
    "# Code starts here\n",
    "    return df.to_csv(filename)\n",
    " # Code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a2502482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "my_dataframe = pd.DataFrame(df)  # Your actual DataFrame here\n",
    "export_to_csv(my_dataframe, \"my_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5475b7",
   "metadata": {},
   "source": [
    "#### T1.4. Reporting (Weightage- 2 marks each)  (ME)\n",
    "1.\tCustomer contact mode made.\n",
    "2.\tAnalysis on attempts made to turn a person into successful depositor.\n",
    "3.\tData analysis on marital status, existing loans, education, profession etc. and its impact on the campaign’s success\n",
    "4.\tSocio-economic analysis of the customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cef19d",
   "metadata": {},
   "source": [
    "### Task 2: Load the dataset and perform preliminary EDA (Exploratory Data Analysis) with key observations and insights- (weightage - 35 marks) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b27add",
   "metadata": {},
   "source": [
    "#### T2.1 Import the data stored above from GITHUB using try and except blocks for modelling and create data frame “df” (weightage 2 marks) AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b7ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_the_dataset_from_github():\n",
    "\n",
    "    # Code starts here\n",
    "\n",
    "\n",
    "    # Code ends here  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12c9f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the result of the dataset\n",
    "df=load_the_dataset_from_github()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6bea5d",
   "metadata": {},
   "source": [
    "#### T2.2\tDrop the columns from the data frame df: 'Customer_id', 'Region_Code_y','Region_Code_x', 'State_Code_x',  \"City_Code\", ' State_Code_y',  'Postal Code', 'City_Name', 'State_Code_y', 'State_Name', 'Region_Code_y', 'Region_Name' . (weightage 2 marks) AE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8bd3e2",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Design a Function `drop_var` to drop/remove specific columns from the Data frame\n",
    "- Dropping columns from a DataFrame involves removing specific columns that are not required for analysis or modeling.\n",
    "- This operation helps streamline the dataset and focus on relevant variables, reducing complexity and improving computational efficiency.\n",
    "- Before dropping columns, it's essential to identify the columns to be removed based on their names or indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a36ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the given variables\n",
    "def drop_var(df):\n",
    "    x = None\n",
    "    # Code starts here\n",
    "\n",
    "    # Code ends here\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48055a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=drop_var(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b89e14",
   "metadata": {},
   "source": [
    "#### T2.3\tChange the order of columns as per data dictionary. (weightage 2 marks) AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbc3a32",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Design a Function `reorder` to rearrange specific columns from the Data frame.\n",
    "- A data dictionary provides metadata about the variables or attributes in a dataset, including their names, descriptions, data types, and order.\n",
    "- It serves as a reference guide for understanding the structure and meaning of the data.\n",
    "- Changing the order of columns in a DataFrame involves rearranging the columns to match the specified order in the data dictionary.\n",
    "- This ensures consistency between the dataset's structure and the documented metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23956d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(df):\n",
    "   \n",
    "   x = None\n",
    "   # Code starts here\n",
    "\n",
    "   # Code ends here\n",
    "   return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69024980",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=reorder(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848de9ca",
   "metadata": {},
   "source": [
    "#### T2.4\tGet the counts of values for the attribute target variable – ‘y’ (weightage 2 marks) AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63be7d5a",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Design a Function `get_y_counts` to get the counts of the most common values from the Data frame\n",
    "- The target variable, often denoted as 'y', is the variable of interest in a predictive modeling task.\n",
    "- It represents the outcome or response variable that the model aims to predict based on the input features.\n",
    "- Getting the counts of values for the target variable provides insights into the distribution of outcomes or classes.\n",
    "- It helps in understanding the balance or imbalance between different classes and assessing the prevalence of each class in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get count of values for the variable y\n",
    "\n",
    "def get_y_counts(df):\n",
    "    y_value_counts = None\n",
    "    # Code starts here\n",
    "\n",
    "    # Code ends here\n",
    "    return y_value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e2c86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=get_y_counts(df)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1a8bdf",
   "metadata": {},
   "source": [
    "#### T2.5 Check missing values in the data in terms of percentage using error handling technique  and do missing value treatment. (weightage 2 marks) AE  \n",
    "\n",
    "\n",
    "#### NOTE:\n",
    "-  Get sum/ percentage of null values to find any missing values if present in data or not, for all the attributes in data frame ‘df’ \n",
    "- Missing values are data points that are absent or unavailable in the dataset, often represented as NaN (Not a Number) or null values.\n",
    "- Detecting missing values is a critical step in data preprocessing to ensure data integrity and reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b30dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_value_check(data):\n",
    "    missing_percentage = None\n",
    "    # Code starts here\n",
    "\n",
    "    # Code ends here\n",
    "    return  missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c0a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value_check(data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ff774",
   "metadata": {},
   "source": [
    "df2=get_all_sum()\n",
    "print(df2)\n",
    "\n",
    "#df.info()\n",
    "#df.head()\n",
    "\n",
    "#df.isnull().sum()\n",
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f664bc7",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Design a Function `rows_columns` to get the number of rows and columns from the Data frame.\n",
    "- The total number of rows and columns in a dataset provides information about its dimensionality.\n",
    "- The number of rows represents the observations or samples in the dataset, while the number of columns represents the variables or features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289bca41",
   "metadata": {},
   "source": [
    "#### T2.6 Check total number of rows and columns in the dataset (Weightage 2 marks )AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fc7be1",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Design a Function `rows_columns` to get the number of rows and columns from the Data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16f8054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rows_columns(df): \n",
    "    x = None\n",
    "    # Code starts here\n",
    "\n",
    "    # Code ends here\n",
    "    return(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a2984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RowsCols=rows_columns(df) \n",
    "print(RowsCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759ef275",
   "metadata": {},
   "source": [
    "#### T2.7 Get the descriptive statistics for all the columns in the data frame. (weightage 2 marks) ME\n",
    "\n",
    "#### NOTE:\n",
    "- Descriptive statistics provide a summary of the key characteristics or properties of the data, helping to understand its distribution, central tendency, dispersion, and shape.\n",
    "- Common descriptive statistics include measures of central tendency (mean, median, mode), measures of dispersion (standard deviation, variance, range), and measures of shape (skewness, kurtosis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5621c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to get descriptive statistics for all numeric columns using describe function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ed8018",
   "metadata": {},
   "source": [
    "#### T2.8\tChange pday values if the value is 999 replace with ‘no’ else ‘yes’ (Weightage 2 marks )AE\n",
    "\n",
    "- changing pdays()values \n",
    "\n",
    "#### NOTE:\n",
    "- Design a Function `pcontacted` to replace pdays values if the value is '999' replace it with 'no' else replace it with a 'yes'\n",
    "- Changing the values in the 'pday' column involves transforming the existing numerical values to categorical labels based on a specified condition.\n",
    "- This transformation allows for a more intuitive interpretation of the data and facilitates subsequent analysis or visualization tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5decddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcontacted(x):\n",
    "\n",
    "    # Code starts here\n",
    "\n",
    "\n",
    "    # Code ends here\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b1540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['pdays'] = df['pdays'].apply(pcontacted)\n",
    "# print(df['pdays'])\n",
    "print(pcontacted(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49b2025",
   "metadata": {},
   "source": [
    "#### T2.9 Rename ‘pdays’ column name with ‘bcontacted’ and get value counts and find number of ‘yes’ and ‘no’. Perform binomial test for proportions on pdays and give inferences based on pvalues (weightage 2 marks) ME\n",
    "\n",
    "#### NOTE: \n",
    "\n",
    "- Renaming the 'pdays' column to 'bcontacted' involves changing the name of the column to better reflect its meaning or purpose in the dataset.\n",
    "- `'bcontacted'` suggests that the column represents whether a contact has been made (binary indicator), which may be more intuitive than 'pdays' (number of days since the client was last contacted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37b7785",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec9377f",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "\n",
    "- Design a Function to determine whether the proportion of successes in a binary outcome variable ('pdays') is significantly different from a specified null hypothesis proportion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e0d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom_test\n",
    "p_value = None\n",
    "inference = None\n",
    "# Assuming 'pdays' is a binary outcome variable with 1 for success and 0 for failure\n",
    "# You would need to replace 'success_count' and 'total_trials' with your actual data\n",
    "# success_count =  # Number of successes (e.g., number of '1's/ 'yes' in 'pdays')\n",
    "# total_trials = # Total number of trials (e.g., total number of observations)\n",
    "\n",
    "# Define the proportion you want to test against\n",
    "\n",
    "\n",
    "# Perform the binomial test\n",
    "\n",
    "\n",
    "# Determine significance based on the p-value\n",
    "\n",
    "\n",
    "\n",
    "print(\"p-value:\", p_value)\n",
    "print(\"Inference:\", inference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding the Functions\n",
    "\n",
    "from scipy.stats import binom_test\n",
    "\n",
    "def binomial_test(success_count, total_trials, null_hypothesis_proportion, alpha=0.05):\n",
    "\n",
    "    # Code starts here\n",
    "    \"\"\"\n",
    "    Perform a binomial test to determine the significance of the observed proportion of successes.\n",
    "\n",
    "    Parameters:\n",
    "    - success_count (int): The number of successes.\n",
    "    - total_trials (int): The total number of trials or observations.\n",
    "    - null_hypothesis_proportion (float): The proportion specified in the null hypothesis.\n",
    "    - alpha (float): The significance level (default is 0.05).\n",
    "\n",
    "    Returns:\n",
    "    - p_value (float): The p-value calculated from the binomial test.\n",
    "    - inference (str): The inference conclusion based on the p-value and significance level.\n",
    "    \"\"\"\n",
    "    # Perform the binomial test\n",
    "\n",
    "    # Determine significance based on the p-value\n",
    "\n",
    "\n",
    "        # Code ends here\n",
    "\n",
    "    return p_value, inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b557c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "success_count = 120  # Number of successes (e.g., number of '1's/ 'yes' in 'pdays')\n",
    "total_trials = 250  # Total number of trials (e.g., total number of observations)\n",
    "null_hypothesis_proportion = 0.5  # Proportion specified in the null hypothesis\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "p_value, inference = binomial_test(success_count, total_trials, null_hypothesis_proportion, alpha)\n",
    "print(\"p-value:\", p_value)\n",
    "print(\"Inference:\", inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfb856a",
   "metadata": {},
   "source": [
    "#### T2.10\tUse the below function/ create a function of your own and drop null values from  ('job'), ('marital'), ('education'), ('housing') (weightage 2 marks) AE\n",
    "\n",
    " #### NOTE:\n",
    "- Design a Function `drop` to drop Null values from the Data Frame\n",
    "- Dropping null values from specific columns is a common data cleaning task to handle missing or incomplete data.\n",
    "- By removing rows with missing values in specific columns, we ensure that the data used for analysis or modeling is complete and reliable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4a678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops nulls\n",
    "import numpy as np\n",
    "\n",
    "def drop(column,df):\n",
    "    # Code starts here\n",
    "    \n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "    # Code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03bfa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop('job',df)\n",
    "drop('marital',df)\n",
    "drop('education',df)\n",
    "drop('housing',df)\n",
    "\n",
    "# df.info()\n",
    "\n",
    "sns.countplot(data=df, x='y',palette='GnBu')\n",
    "plt.show()\n",
    "\n",
    "df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a233358",
   "metadata": {},
   "source": [
    "#### T2.11\tPerform data separation store all categorical variables in as ‘cat’ and All numeric variables in as ‘Numeric’ (weightage 2 marks) ME\n",
    "\n",
    "#### NOTE:\n",
    "- Data separation involves segregating different types of variables in a dataset based on their data types or characteristics.\n",
    "- we aim to separate categorical variables, which represent qualitative attributes, from numeric variables, which represent quantitative attributes.\n",
    "- Categorical variables are qualitative variables that represent categories or groups.\n",
    "- Numeric variables are quantitative variables that represent numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae057357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all catogorical variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ee938",
   "metadata": {},
   "source": [
    "#### T2.12\tCreate countplot for all categorical variables (weightage 2 marks) ME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6fb8a7",
   "metadata": {},
   "source": [
    "#### T2.12\tCreate countplot for all categorical variables (weightage 2 marks) ME\n",
    "- Count plots are graphical representations that display the frequency or count of observations within different categories of a categorical variable.\n",
    "- They provide a visual summary of the distribution of categorical data, making it easier to understand the relative frequencies of different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c3bef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "\n",
    "# code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b435c7",
   "metadata": {},
   "source": [
    "#### T2.13\tChange datatype for ‘month’ and ‘day_of_week’ as ‘str’ (weightage 2 marks) ME\n",
    "\n",
    "- Numbers: to get number of numeric variables\n",
    "- Changing the data type of columns to 'str' converts the numerical or categorical values in the columns to string format.\n",
    "- This conversion is useful when treating these columns as categorical variables or when the values represent labels rather than numeric quantities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227206e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code starts here\n",
    "\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5cd886",
   "metadata": {},
   "source": [
    "#### T2.14\tCreate histogram to know the Distribution of Attributes in the data frame df and check for normality (weightage 2 marks) ME\n",
    "\n",
    "- Histograms are graphical representations of the distribution of numerical data.\n",
    "- They provide a visual summary of the frequency or count of observations within different intervals, or \"bins,\" of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b439d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code starts here\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3afabdc",
   "metadata": {},
   "source": [
    "#### T2.15\tGet Descriptive Statistics for all numeric variables (weightage 2 marks) ME\n",
    "\n",
    "- Hint: Using the code: np.log(df['campaign'] + 1) perform log transformation and create an histogram.\n",
    "\n",
    "- To get descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eaf311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6c386cd",
   "metadata": {},
   "source": [
    "#### T2.16\tDrop variable duration from df (weightage 1 marks) ME\n",
    "\n",
    "- drop duration Coloumn\n",
    "- Dropping a variable can impact subsequent analysis, such as descriptive statistics, exploratory data analysis, or predictive modeling.\n",
    "- Ensure that dropping the \"duration\" variable does not compromise the integrity or quality of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a7834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39638926",
   "metadata": {},
   "source": [
    "#### T2.17\tCreate Visualizations for: Correlations and Scatter plot and find with relevant statistical function Pearson's coefficient, if there is correlation or not, based on p values (weightage 2 marks) ME\n",
    "`Correlation Heatmap`:\n",
    "- Use seaborn's heatmap function to create a correlation heatmap.\n",
    "- The heatmap displays correlation coefficients between pairs of variables.\n",
    "\n",
    "`Scatter Plot`:\n",
    "- Use seaborn's scatterplot function to create scatter plots between pairs of variables.\n",
    "- Scatter plots visualize the relationship between two continuous variables.\n",
    "\n",
    "`Pearson's Correlation Coefficient`:\n",
    "- Calculate Pearson's correlation coefficient (also known as Pearson's r) to quantify the strength and direction of the linear relationship between two continuous variables.\n",
    "- Pearson's r ranges from -1 to 1, where:\n",
    "    - 1 indicates a perfect positive linear relationship,\n",
    "    - -1 indicates a perfect negative linear relationship, and 0 indicates no linear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a12fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "641a58c3",
   "metadata": {},
   "source": [
    "#### T2.18\tPerform Feature Engineering for all the features using get_dummies function except for target feature y  (weightage 2 marks) AE\n",
    "\n",
    "#### NOTE:\n",
    "- This function `dummy_function` should convert categorical variables into dummy variables using one-hot encoding, a common preprocessing technique in machine learning.\n",
    "- It must take a DataFrame (data) containing categorical variables as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285184f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features = df.iloc[:,:-1]\n",
    "#print(df_features)\n",
    "\n",
    "def dummy_function(data):\n",
    "    # df_features = df.iloc[:,:-1]\n",
    "    df_features1 = None\n",
    "\n",
    "    # Code starts here\n",
    "\n",
    "    # Code ends here\n",
    "    return df_features1\n",
    "\n",
    "#display(df_features.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428b24ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features=dummy_function(df) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690bbdae",
   "metadata": {},
   "source": [
    "### Task 3: Build  model for predicting after splitting the dataset (weightage - 15 marks) \n",
    "\n",
    "#### NOTE:\n",
    "- Split the dataset into X and y, with test_size=0.33 and random_state=42\t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f9956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b79a927",
   "metadata": {},
   "source": [
    "#### T3.1\tRandomForestClassifier(n_estimators=100, random_state=42), n_features_to_select=20) (weightage 5 marks) ME\n",
    "\n",
    "- Save the code for model versioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08c38d1",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Build a machine learning model for classification using random forest.\n",
    "- Employ recursive feature elimination (RFE) for feature selection.\n",
    "- The function should take input features X and target variable y.\n",
    "- The function can iterate over a range of n_features, which specifies the number of features to select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3deca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def select_features(X, y, test_size=0.2, n_features=[20]):\n",
    "    features = None\n",
    "    np.warnings.filterwarnings('ignore')\n",
    "\n",
    "    # Code starts here\n",
    "\n",
    "\n",
    "   # Code ends here\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb14e2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = select_features(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceca29d1",
   "metadata": {},
   "source": [
    "### Classification model\n",
    "#### T3.2\tCreate KNN model using the following parameters, KNeighborsClassifier(n_neighbors=10) Save the code for model versioning (weightage 5 marks) ME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f703fe",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Build a machine learning model for classification using KNeighbors.\n",
    "- The function should take input features (df_features), target feature (target_feature), and a list of features to consider (features).\n",
    "- The function can iterate over a range of n_features, which specifies the number of features to select.\n",
    "- The function must create a KNN classifier with the specified number of neighbors and fits it to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63682edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def build_knn_model(df_features, target_feature, features):\n",
    "    knn = None\n",
    "\n",
    "    # Code starts here\n",
    "   \n",
    "    # Code ends here\n",
    "    \n",
    "    return knn  # Returning the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debe42fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to build the KNN model\n",
    "knn_model = build_knn_model(df_features, df['y'], select)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2302fb1f",
   "metadata": {},
   "source": [
    "#### T3.3\tCreate a Gradient boosting classifier model using the following parameters , GradientBoostingClassifier with options: n_estimators=100, random_state=42, max_depth=1. Save the code for model versioning (weightage 5 marks) ME\n",
    "\n",
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19047b3e",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Build a machine learning model for classification using Gradient Boosting.\n",
    "- define a function `build_gbrt_model` that takes input features X, target variable y, and some optional parameters like random_state, n_estimators, max_depth, and test_size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def build_gbrt_model(X, y, random_state=42, n_estimators=100, max_depth=1, test_size=0.2):\n",
    "    gbrt = None\n",
    "\n",
    "    # Code starts here\n",
    "\n",
    "\n",
    "    # Code ends here\n",
    "    return gbrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18d6075",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt=build_gbrt_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3962ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e341d6",
   "metadata": {},
   "source": [
    "### Task 4: Evaluate the performance of the model using the right evaluation metrics.(weightage - 20 marks)                                                                                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b5461f",
   "metadata": {},
   "source": [
    "#### T4.1\tEvaluate the above models by getting accuracy, Precision, Recall, F1 Score, Kappa Score\t(weightage - 4 marks) AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be66511",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dbc6f2",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "\n",
    "-  Define a function which takes input as the test features (X_test), test labels (y_test), and the trained model (model).\n",
    "- Predict labels for the test set and then calculate evaluation metrics such as accuracy, precision, recall, and Cohen's kappa.\n",
    "**Range of results:** \n",
    "\n",
    "    -if accuracy +/-0.10  \n",
    "    -if precision +/-0.10  \n",
    "    -if recall +/-0.10  \n",
    "    -if kappa +/-0.10  \n",
    "\n",
    "    - all results are correct: 100%: 4 marks\n",
    "    - otherwise score: 3 marks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae351abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, cohen_kappa_score\n",
    "\n",
    "def evaluate_model1(X_test, y_test, model):\n",
    "    accuracy,precision,recall,kappa = 0.0,0.0,0.0,0.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Code ends here\n",
    "    \n",
    "   \n",
    "    return accuracy, precision, recall, kappa\n",
    "\n",
    "# Example usage:\n",
    "# accuracy, precision, recall, kappa = evaluate_model(X_test, y_test, your_model)  # Replace your_model with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e991cb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function\n",
    "accuracy=evaluate_model1(X_test, y_test,select)[0]\n",
    "precision=evaluate_model1(X_test, y_test,select)[1]\n",
    "recall=evaluate_model1(X_test, y_test,select)[2]\n",
    "kappa=evaluate_model1(X_test, y_test,select)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f24f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f25ad1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b87055dd",
   "metadata": {},
   "source": [
    "### Knn model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42d2e86",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "\n",
    "- Evaluate a saved k-nearest neighbors (KNN) model using various classification metrics.\n",
    "- The Function should take a input the trained KNN model (knn_model), test features (X_test), and test labels (y_test).\n",
    "- Then it must predict labels for the test set using the provided KNN model and calculates evaluation metrics such as accuracy, precision, recall, and Cohen's kappa.\n",
    "\n",
    "\n",
    "\n",
    "**Range of results: \n",
    "\n",
    "-if accuracy +/-0.10  \n",
    "-if precision +/-0.10  \n",
    "-if recall +/-0.10  \n",
    "-if kappa +/-0.10  \n",
    "\n",
    "- all results are correct: 100%: 4 marks\n",
    "- otherwise score: 3 marks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433b2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, cohen_kappa_score\n",
    "\n",
    "def evaluate_saved_knn_model(knn_model, X_test, y_test):\n",
    "    accuracy, precision, recall, kappa = 0.0,0.0,0.0,0.0\n",
    "\n",
    "    # Code starts here\n",
    "\n",
    "    # Code ends here\n",
    "    \n",
    "    return accuracy, precision, recall, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfe0f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function\n",
    "accuracy=evaluate_saved_knn_model(knn_model, X_test, y_test)[0]\n",
    "precision=evaluate_saved_knn_model(knn_model, X_test, y_test)[1]\n",
    "recall=evaluate_saved_knn_model(knn_model, X_test, y_test)[2]\n",
    "kappa=evaluate_saved_knn_model(knn_model, X_test, y_test)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be31f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946fb0b5",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b3cc7",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Define a Function that evaluates a Gradient Boosting Classifier model (gbrt) using various classification metrics.\n",
    "- The function must calculate metrics such as accuracy, precision, recall, and Cohen's kappa, based on the predictions made by the model on the test set.\n",
    "\n",
    "\n",
    "\n",
    "**Range of results: \n",
    "\n",
    "-if accuracy +/-0.10  \n",
    "-if precision +/-0.10  \n",
    "-if recall +/-0.10  \n",
    "-if kappa +/-0.10  \n",
    "\n",
    "- all results are correct: 100%: 4 marks\n",
    "- otherwise score: 3 marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e65a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gbrt_model(gbrt, X_test, y_test):\n",
    "    accuracy, precision, recall, kappa = 0.0,0.0,0.0,0.0\n",
    "\n",
    "    # Code starts here\n",
    "\n",
    "\n",
    "    # Code ends here\n",
    "    \n",
    "    return accuracy, precision, recall, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5bca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function\n",
    "accuracy=evaluate_gbrt_model(gbrt, X_test, y_test)[0]\n",
    "precision=evaluate_gbrt_model(gbrt, X_test, y_test)[1]\n",
    "recall=evaluate_gbrt_model(gbrt, X_test, y_test)[2]\n",
    "kappa=evaluate_gbrt_model(gbrt, X_test, y_test)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c0775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc55704",
   "metadata": {},
   "source": [
    "#### T.4.2 Perform Hyperparameter tuning. Re build the model with best suitable modelling technique (weightage 5 marks) ME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46237ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "\n",
    "\n",
    "# Create the Gradient Boosting Classifier model\n",
    "\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validation\n",
    "\n",
    "\n",
    "# Fit the Grid Search to find the best parameters\n",
    "\n",
    "# Get the best parameters and best score\n",
    "\n",
    "\n",
    "# Rebuild the model with the best parameters\n",
    "\n",
    "\n",
    "# Print the best parameters and best score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befeba79",
   "metadata": {},
   "source": [
    "#### T.4.3 Using Lime/SHAP libraries, explain the prediction of your classification model and give inferences.   (weightage 3 marks) ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feeae8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "643ad8b5",
   "metadata": {},
   "source": [
    "#### T4.4 Implement unit test case and deploy the above models using Flask/ Stream lit\t(weightage - 8 marks) ME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d82466",
   "metadata": {},
   "source": [
    "### Task 5: Summarize the findings of the analysis and draw conclusions with PPT / PDF. (weightage - 15 marks) (ME) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969c126a",
   "metadata": {},
   "source": [
    "##### Classification Model Conclusions\n",
    "\n",
    "''' The Knn modelwith a test set score of 0.892 was obtained which is fairly good\n",
    "    but the gradient models are more effective\n",
    "    \n",
    "    By using the reduced dataset and the complete dataset to build the model, \n",
    "    we obtained the same results (test score of 0.90). \n",
    "    the reduced dataset, thought, run a bit faster (0.82 vs 1.06)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d6d7d2",
   "metadata": {},
   "source": [
    "**Final Submission guidelines:**\n",
    "- Download the Jupyter notebook in the format of html. \n",
    "- Upload it in the lumen (UNext LMS)\n",
    "- Take a screenshot of T4.4 (Deployment) and upload it in the lumen (UNext LMS)\n",
    "- Summarized PPT/ PDF prepared in Task 5 to be uploaded in the lumen (UNext LMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb091539",
   "metadata": {},
   "source": [
    "-------------------------------------------------- **ASSESSMENT ENDS HERE** ---------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
